{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.4-overfitting-and-underfitting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/alzayats/Google_Colab/blob/master/4_4_overfitting_and_underfitting.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WyDAv5jrRbNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba0c0bd5-4ac9-488e-8ba3-c3d53a17fae2"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Now_YoBzRbNu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Overfitting and underfitting\n",
        "\n",
        "This notebook contains the code samples found in Chapter 3, Section 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "In all the examples we saw in the previous chapter -- movie review sentiment prediction, topic classification, and house price regression -- \n",
        "we could notice that the performance of our model on the held-out validation data would always peak after a few epochs and would then start \n",
        "degrading, i.e. our model would quickly start to _overfit_ to the training data. Overfitting happens in every single machine learning \n",
        "problem. Learning how to deal with overfitting is essential to mastering machine learning.\n",
        "\n",
        "The fundamental issue in machine learning is the tension between optimization and generalization. \"Optimization\" refers to the process of \n",
        "adjusting a model to get the best performance possible on the training data (the \"learning\" in \"machine learning\"), while \"generalization\" \n",
        "refers to how well the trained model would perform on data it has never seen before. The goal of the game is to get good generalization, of \n",
        "course, but you do not control generalization; you can only adjust the model based on its training data.\n",
        "\n",
        "At the beginning of training, optimization and generalization are correlated: the lower your loss on training data, the lower your loss on \n",
        "test data. While this is happening, your model is said to be _under-fit_: there is still progress to be made; the network hasn't yet \n",
        "modeled all relevant patterns in the training data. But after a certain number of iterations on the training data, generalization stops \n",
        "improving, validation metrics stall then start degrading: the model is then starting to over-fit, i.e. is it starting to learn patterns \n",
        "that are specific to the training data but that are misleading or irrelevant when it comes to new data.\n",
        "\n",
        "To prevent a model from learning misleading or irrelevant patterns found in the training data, _the best solution is of course to get \n",
        "more training data_. A model trained on more data will naturally generalize better. When that is no longer possible, the next best solution \n",
        "is to modulate the quantity of information that your model is allowed to store, or to add constraints on what information it is allowed to \n",
        "store. If a network can only afford to memorize a small number of patterns, the optimization process will force it to focus on the most \n",
        "prominent patterns, which have a better chance of generalizing well.\n",
        "\n",
        "The processing of fighting overfitting in this way is called _regularization_. Let's review some of the most common regularization \n",
        "techniques, and let's apply them in practice to improve our movie classification model from  the previous chapter."
      ]
    },
    {
      "metadata": {
        "id": "wih8BZHQRbNy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: in this notebook we will be using the IMDB test set as our validation set. It doesn't matter in this context.\n",
        "\n",
        "Let's prepare the data using the code from Chapter 3, Section 5:"
      ]
    },
    {
      "metadata": {
        "id": "Uhat65vqRbN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
        "    return results\n",
        "\n",
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)\n",
        "# Our vectorized labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Q27fYRSRbOA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fighting overfitting\n",
        "\n",
        "## Reducing the network's size\n",
        "\n",
        "\n",
        "The simplest way to prevent overfitting is to reduce the size of the model, i.e. the number of learnable parameters in the model (which is \n",
        "determined by the number of layers and the number of units per layer). In deep learning, the number of learnable parameters in a model is \n",
        "often referred to as the model's \"capacity\". Intuitively, a model with more parameters will have more \"memorization capacity\" and therefore \n",
        "will be able to easily learn a perfect dictionary-like mapping between training samples and their targets, a mapping without any \n",
        "generalization power. For instance, a model with 500,000 binary parameters could easily be made to learn the class of every digits in the \n",
        "MNIST training set: we would only need 10 binary parameters for each of the 50,000 digits. Such a model would be useless for classifying \n",
        "new digit samples. Always keep this in mind: deep learning models tend to be good at fitting to the training data, but the real challenge \n",
        "is generalization, not fitting.\n",
        "\n",
        "On the other hand, if the network has limited memorization resources, it will not be able to learn this mapping as easily, and thus, in \n",
        "order to minimize its loss, it will have to resort to learning compressed representations that have predictive power regarding the targets \n",
        "-- precisely the type of representations that we are interested in. At the same time, keep in mind that you should be using models that have \n",
        "enough parameters that they won't be underfitting: your model shouldn't be starved for memorization resources. There is a compromise to be \n",
        "found between \"too much capacity\" and \"not enough capacity\".\n",
        "\n",
        "Unfortunately, there is no magical formula to determine what the right number of layers is, or what the right size for each layer is. You \n",
        "will have to evaluate an array of different architectures (on your validation set, not on your test set, of course) in order to find the \n",
        "right model size for your data. The general workflow to find an appropriate model size is to start with relatively few layers and \n",
        "parameters, and start increasing the size of the layers or adding new layers until you see diminishing returns with regard to the \n",
        "validation loss.\n",
        "\n",
        "Let's try this on our movie review classification network. Our original network was as such:"
      ]
    },
    {
      "metadata": {
        "id": "5D8APyosRbOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "original_model = models.Sequential()\n",
        "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "original_model.add(layers.Dense(16, activation='relu'))\n",
        "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "original_model.compile(optimizer='rmsprop',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPdIcC7tRbOQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's try to replace it with this smaller network:"
      ]
    },
    {
      "metadata": {
        "id": "Nd0vz-u8RbOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "smaller_model = models.Sequential()\n",
        "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
        "smaller_model.add(layers.Dense(4, activation='relu'))\n",
        "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "smaller_model.compile(optimizer='rmsprop',\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfwJB9UjRbOe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here's a comparison of the validation losses of the original network and the smaller network. The dots are the validation loss values of \n",
        "the smaller network, and the crosses are the initial network (remember: a lower validation loss signals a better model)."
      ]
    },
    {
      "metadata": {
        "id": "6YLWzO96RbOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "ab38f209-094e-4ddd-9a23-7e7254c1c4d2"
      },
      "cell_type": "code",
      "source": [
        "original_hist = original_model.fit(x_train, y_train,\n",
        "                                   epochs=20,\n",
        "                                   batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 4s 149us/step - loss: 0.4434 - acc: 0.8239 - val_loss: 0.3292 - val_acc: 0.8838\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.2577 - acc: 0.9082 - val_loss: 0.2860 - val_acc: 0.8884\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.1992 - acc: 0.9295 - val_loss: 0.2823 - val_acc: 0.8887\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.1668 - acc: 0.9412 - val_loss: 0.2938 - val_acc: 0.8849\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 129us/step - loss: 0.1438 - acc: 0.9501 - val_loss: 0.3112 - val_acc: 0.8807\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.1261 - acc: 0.9553 - val_loss: 0.3489 - val_acc: 0.8716\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 3s 127us/step - loss: 0.1111 - acc: 0.9616 - val_loss: 0.3583 - val_acc: 0.8724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.0983 - acc: 0.9669 - val_loss: 0.3937 - val_acc: 0.8672\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 129us/step - loss: 0.0851 - acc: 0.9713 - val_loss: 0.4331 - val_acc: 0.8609\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.0758 - acc: 0.9752 - val_loss: 0.4984 - val_acc: 0.8529\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0693 - acc: 0.9776 - val_loss: 0.4807 - val_acc: 0.8604\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0571 - acc: 0.9823 - val_loss: 0.5155 - val_acc: 0.8565\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 129us/step - loss: 0.0516 - acc: 0.9842 - val_loss: 0.5323 - val_acc: 0.8591\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.0424 - acc: 0.9879 - val_loss: 0.6269 - val_acc: 0.8469\n",
            "Epoch 15/20\n",
            " 6656/25000 [======>.......................] - ETA: 1s - loss: 0.0281 - acc: 0.9934"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0371 - acc: 0.9892 - val_loss: 0.6052 - val_acc: 0.8552\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0313 - acc: 0.9908 - val_loss: 0.6417 - val_acc: 0.8546\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0268 - acc: 0.9930 - val_loss: 0.6859 - val_acc: 0.8521\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 129us/step - loss: 0.0234 - acc: 0.9942 - val_loss: 0.7361 - val_acc: 0.8495\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0168 - acc: 0.9961 - val_loss: 0.7537 - val_acc: 0.8508\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 128us/step - loss: 0.0151 - acc: 0.9964 - val_loss: 0.8398 - val_acc: 0.8424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e_RspyisRbO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "396aef78-8cf4-4943-9c60-4f369e435b07"
      },
      "cell_type": "code",
      "source": [
        "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
        "                                       epochs=20,\n",
        "                                       batch_size=512,\n",
        "                                       validation_data=(x_test, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 3s 134us/step - loss: 0.5800 - acc: 0.7025 - val_loss: 0.5303 - val_acc: 0.7586\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 124us/step - loss: 0.4841 - acc: 0.8456 - val_loss: 0.4873 - val_acc: 0.8287\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.4387 - acc: 0.8929 - val_loss: 0.4661 - val_acc: 0.8506\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.4075 - acc: 0.9157 - val_loss: 0.4541 - val_acc: 0.8628\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 124us/step - loss: 0.3830 - acc: 0.9310 - val_loss: 0.4501 - val_acc: 0.8639\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 125us/step - loss: 0.3620 - acc: 0.9410 - val_loss: 0.4434 - val_acc: 0.8716\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.3427 - acc: 0.9513 - val_loss: 0.4561 - val_acc: 0.8638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.3262 - acc: 0.9556 - val_loss: 0.4483 - val_acc: 0.8692\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 125us/step - loss: 0.3100 - acc: 0.9614 - val_loss: 0.4789 - val_acc: 0.8598\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 124us/step - loss: 0.2958 - acc: 0.9658 - val_loss: 0.4806 - val_acc: 0.8608\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 122us/step - loss: 0.2816 - acc: 0.9684 - val_loss: 0.4775 - val_acc: 0.8621\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.2688 - acc: 0.9721 - val_loss: 0.4891 - val_acc: 0.8614\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 124us/step - loss: 0.2565 - acc: 0.9737 - val_loss: 0.5127 - val_acc: 0.8583\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 3s 124us/step - loss: 0.2455 - acc: 0.9757 - val_loss: 0.5442 - val_acc: 0.8563\n",
            "Epoch 15/20\n",
            " 8704/25000 [=========>....................] - ETA: 1s - loss: 0.2317 - acc: 0.9793"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 122us/step - loss: 0.2338 - acc: 0.9780 - val_loss: 0.5048 - val_acc: 0.8619\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.2238 - acc: 0.9796 - val_loss: 0.5559 - val_acc: 0.8567\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 122us/step - loss: 0.2149 - acc: 0.9805 - val_loss: 0.5723 - val_acc: 0.8568\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 122us/step - loss: 0.2051 - acc: 0.9822 - val_loss: 0.5758 - val_acc: 0.8574\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 122us/step - loss: 0.1969 - acc: 0.9831 - val_loss: 0.5532 - val_acc: 0.8538\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 123us/step - loss: 0.1893 - acc: 0.9834 - val_loss: 0.6556 - val_acc: 0.8506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1gbCaIwCRbPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = range(1, 21)\n",
        "original_val_loss = original_hist.history['val_loss']\n",
        "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfzNRWOVRbPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "3cc834f4-520b-4737-9f6d-c8f2d12aee97"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# b+ is for \"blue cross\"\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdee4c3b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_FWaijHaRbPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "As you can see, the smaller network starts overfitting later than the reference one (after 6 epochs rather than 4) and its performance \n",
        "degrades much more slowly once it starts overfitting.\n",
        "\n",
        "Now, for kicks, let's add to this benchmark a network that has much more capacity, far more than the problem would warrant:"
      ]
    },
    {
      "metadata": {
        "id": "01h36XAbRbPj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bigger_model = models.Sequential()\n",
        "bigger_model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
        "bigger_model.add(layers.Dense(512, activation='relu'))\n",
        "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "bigger_model.compile(optimizer='rmsprop',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9oTtiE-RbPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "cd9c451c-623f-4a40-e6d6-7ba62537afe3"
      },
      "cell_type": "code",
      "source": [
        "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
        "                                     epochs=20,\n",
        "                                     batch_size=512,\n",
        "                                     validation_data=(x_test, y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 19s 741us/step - loss: 0.4687 - acc: 0.7924 - val_loss: 0.2836 - val_acc: 0.8881\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 18s 724us/step - loss: 0.2247 - acc: 0.9120 - val_loss: 0.3312 - val_acc: 0.8638\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 18s 723us/step - loss: 0.1392 - acc: 0.9484 - val_loss: 0.3056 - val_acc: 0.8863\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 18s 723us/step - loss: 0.0722 - acc: 0.9790 - val_loss: 0.4091 - val_acc: 0.8839\n",
            "Epoch 5/20\n",
            "20992/25000 [========================>.....] - ETA: 2s - loss: 0.0791 - acc: 0.9848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 18s 719us/step - loss: 0.0678 - acc: 0.9870 - val_loss: 0.4790 - val_acc: 0.8833\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 18s 720us/step - loss: 0.0628 - acc: 0.9883 - val_loss: 0.4610 - val_acc: 0.8788\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 18s 723us/step - loss: 0.0026 - acc: 0.9998 - val_loss: 0.6112 - val_acc: 0.8814\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 18s 722us/step - loss: 3.0909e-04 - acc: 1.0000 - val_loss: 1.6451 - val_acc: 0.7869\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 18s 724us/step - loss: 0.0786 - acc: 0.9919 - val_loss: 0.7221 - val_acc: 0.8796\n",
            "Epoch 10/20\n",
            " 7680/25000 [========>.....................] - ETA: 8s - loss: 5.0355e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 18s 724us/step - loss: 4.1736e-05 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.8781\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 18s 724us/step - loss: 7.6134e-06 - acc: 1.0000 - val_loss: 0.9011 - val_acc: 0.8774\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 18s 720us/step - loss: 1.1477e-06 - acc: 1.0000 - val_loss: 0.9703 - val_acc: 0.8778\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 18s 722us/step - loss: 2.6722e-07 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.8784\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 18s 722us/step - loss: 1.4265e-07 - acc: 1.0000 - val_loss: 1.0692 - val_acc: 0.8782\n",
            "Epoch 15/20\n",
            " 4096/25000 [===>..........................] - ETA: 10s - loss: 1.2198e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 18s 723us/step - loss: 1.2137e-07 - acc: 1.0000 - val_loss: 1.0856 - val_acc: 0.8781\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 18s 721us/step - loss: 1.1584e-07 - acc: 1.0000 - val_loss: 1.0967 - val_acc: 0.8780\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 18s 724us/step - loss: 1.1348e-07 - acc: 1.0000 - val_loss: 1.1045 - val_acc: 0.8782\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 18s 720us/step - loss: 1.1226e-07 - acc: 1.0000 - val_loss: 1.1091 - val_acc: 0.8782\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 18s 723us/step - loss: 1.1150e-07 - acc: 1.0000 - val_loss: 1.1129 - val_acc: 0.8781\n",
            "Epoch 20/20\n",
            " 3584/25000 [===>..........................] - ETA: 10s - loss: 1.1093e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 18s 720us/step - loss: 1.1109e-07 - acc: 1.0000 - val_loss: 1.1171 - val_acc: 0.8781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IdWNdf8xRbP6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how the bigger network fares compared to the reference one. The dots are the validation loss values of the bigger network, and the \n",
        "crosses are the initial network."
      ]
    },
    {
      "metadata": {
        "id": "X-3MlT5sRbP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "8e77c331-7bc8-4a28-e29c-047b35663407"
      },
      "cell_type": "code",
      "source": [
        "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdef36a7fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "H-r8_8TGRbQQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The bigger network starts overfitting almost right away, after just one epoch, and overfits much more severely. Its validation loss is also \n",
        "more noisy.\n",
        "\n",
        "Meanwhile, here are the training losses for our two networks:"
      ]
    },
    {
      "metadata": {
        "id": "Oy1iYAvdRbQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "08e9ee7a-3033-4486-bcc0-95d51eb1e618"
      },
      "cell_type": "code",
      "source": [
        "original_train_loss = original_hist.history['loss']\n",
        "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
        "\n",
        "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDKENwAAJvP/5rdYqdOlL+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdef3d8f8d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DBXauPkHRbQk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see, the bigger network gets its training loss near zero very quickly. The more capacity the network has, the quicker it will be \n",
        "able to model the training data (resulting in a low training loss), but the more susceptible it is to overfitting (resulting in a large \n",
        "difference between the training and validation loss)."
      ]
    },
    {
      "metadata": {
        "id": "uJmn6iuVRbQo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding weight regularization\n",
        "\n",
        "\n",
        "You may be familiar with _Occam's Razor_ principle: given two explanations for something, the explanation most likely to be correct is the \n",
        "\"simplest\" one, the one that makes the least amount of assumptions. This also applies to the models learned by neural networks: given some \n",
        "training data and a network architecture, there are multiple sets of weights values (multiple _models_) that could explain the data, and \n",
        "simpler models are less likely to overfit than complex ones.\n",
        "\n",
        "A \"simple model\" in this context is a model where the distribution of parameter values has less entropy (or a model with fewer \n",
        "parameters altogether, as we saw in the section above). Thus a common way to mitigate overfitting is to put constraints on the complexity \n",
        "of a network by forcing its weights to only take small values, which makes the distribution of weight values more \"regular\". This is called \n",
        "\"weight regularization\", and it is done by adding to the loss function of the network a _cost_ associated with having large weights. This \n",
        "cost comes in two flavors:\n",
        "\n",
        "* L1 regularization, where the cost added is proportional to the _absolute value of the weights coefficients_ (i.e. to what is called the \n",
        "\"L1 norm\" of the weights).\n",
        "* L2 regularization, where the cost added is proportional to the _square of the value of the weights coefficients_ (i.e. to what is called \n",
        "the \"L2 norm\" of the weights). L2 regularization is also called _weight decay_ in the context of neural networks. Don't let the different \n",
        "name confuse you: weight decay is mathematically the exact same as L2 regularization.\n",
        "\n",
        "In Keras, weight regularization is added by passing _weight regularizer instances_ to layers as keyword arguments. Let's add L2 weight \n",
        "regularization to our movie review classification network:"
      ]
    },
    {
      "metadata": {
        "id": "kB1lu4iqRbQr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "l2_model = models.Sequential()\n",
        "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu', input_shape=(10000,)))\n",
        "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu'))\n",
        "l2_model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRRDyA8KRbQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l2_model.compile(optimizer='rmsprop',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvTWhB59RbRA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`l2(0.001)` means that every coefficient in the weight matrix of the layer will add `0.001 * weight_coefficient_value` to the total loss of \n",
        "the network. Note that because this penalty is _only added at training time_, the loss for this network will be much higher at training \n",
        "than at test time.\n",
        "\n",
        "Here's the impact of our L2 regularization penalty:"
      ]
    },
    {
      "metadata": {
        "id": "y0iPHaKGRbRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "3a081f2f-1a20-4f21-847a-f45c78faad48"
      },
      "cell_type": "code",
      "source": [
        "l2_model_hist = l2_model.fit(x_train, y_train,\n",
        "                             epochs=20,\n",
        "                             batch_size=512,\n",
        "                             validation_data=(x_test, y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 4s 150us/step - loss: 0.4867 - acc: 0.8162 - val_loss: 0.3878 - val_acc: 0.8669\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.3095 - acc: 0.9059 - val_loss: 0.3303 - val_acc: 0.8890\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.2651 - acc: 0.9205 - val_loss: 0.3295 - val_acc: 0.8867\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.2452 - acc: 0.9293 - val_loss: 0.3401 - val_acc: 0.8822\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.2314 - acc: 0.9350 - val_loss: 0.3811 - val_acc: 0.8680\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.2230 - acc: 0.9388 - val_loss: 0.3654 - val_acc: 0.8756\n",
            "Epoch 7/20\n",
            "24064/25000 [===========================>..] - ETA: 0s - loss: 0.2150 - acc: 0.9425"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.2163 - acc: 0.9414 - val_loss: 0.3746 - val_acc: 0.8739\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.2100 - acc: 0.9448 - val_loss: 0.3732 - val_acc: 0.8756\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.2040 - acc: 0.9466 - val_loss: 0.3758 - val_acc: 0.8751\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.2005 - acc: 0.9502 - val_loss: 0.3817 - val_acc: 0.8747\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.1949 - acc: 0.9491 - val_loss: 0.3829 - val_acc: 0.8762\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1921 - acc: 0.9517 - val_loss: 0.3935 - val_acc: 0.8743\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1883 - acc: 0.9534 - val_loss: 0.3953 - val_acc: 0.8734\n",
            "Epoch 14/20\n",
            "10752/25000 [===========>..................] - ETA: 1s - loss: 0.1745 - acc: 0.9606"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1824 - acc: 0.9565 - val_loss: 0.4373 - val_acc: 0.8627\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1826 - acc: 0.9569 - val_loss: 0.4468 - val_acc: 0.8602\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.1767 - acc: 0.9588 - val_loss: 0.4516 - val_acc: 0.8627\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1736 - acc: 0.9602 - val_loss: 0.4187 - val_acc: 0.8708\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1713 - acc: 0.9615 - val_loss: 0.4366 - val_acc: 0.8672\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1669 - acc: 0.9648 - val_loss: 0.4460 - val_acc: 0.8649\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1621 - acc: 0.9661 - val_loss: 0.4362 - val_acc: 0.8697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jcjpEpdaRbRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "f605fc9c-b614-4674-a03e-1e0d183b5b1b"
      },
      "cell_type": "code",
      "source": [
        "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdeeae25fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Bs96PseQRbRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "As you can see, the model with L2 regularization (dots) has become much more resistant to overfitting than the reference model (crosses), \n",
        "even though both models have the same number of parameters.\n",
        "\n",
        "As alternatives to L2 regularization, you could use one of the following Keras weight regularizers:"
      ]
    },
    {
      "metadata": {
        "id": "iNfQNbxLRbRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "collapsed": true,
        "outputId": "de244373-ebe7-4bd1-c6d2-c3d1f12b6c72"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# L1 regularization\n",
        "regularizers.l1(0.001)\n",
        "\n",
        "# L1 and L2 regularization at the same time\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x7fdeeae25da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "q1HlN7mURbRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding dropout\n",
        "\n",
        "\n",
        "Dropout is one of the most effective and most commonly used regularization techniques for neural networks, developed by Hinton and his \n",
        "students at the University of Toronto. Dropout, applied to a layer, consists of randomly \"dropping out\" (i.e. setting to zero) a number of \n",
        "output features of the layer during training. Let's say a given layer would normally have returned a vector `[0.2, 0.5, 1.3, 0.8, 1.1]` for a \n",
        "given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. `[0, 0.5, \n",
        "1.3, 0, 1.1]`. The \"dropout rate\" is the fraction of the features that are being zeroed-out; it is usually set between 0.2 and 0.5. At test \n",
        "time, no units are dropped out, and instead the layer's output values are scaled down by a factor equal to the dropout rate, so as to \n",
        "balance for the fact that more units are active than at training time.\n",
        "\n",
        "Consider a Numpy matrix containing the output of a layer, `layer_output`, of shape `(batch_size, features)`. At training time, we would be \n",
        "zero-ing out at random a fraction of the values in the matrix:"
      ]
    },
    {
      "metadata": {
        "id": "6_JZZl7tRbRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "collapsed": true,
        "outputId": "f8906422-23c3-403f-a11e-2a398bf51f0b"
      },
      "cell_type": "code",
      "source": [
        "# At training time: we drop out 50% of the units in the output\n",
        "layer_output *= np.randint(0, high=2, size=layer_output.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-17e51ff1abf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_output' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "EDkbFDuyRbR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "At test time, we would be scaling the output down by the dropout rate. Here we scale by 0.5 (because we were previous dropping half the \n",
        "units):"
      ]
    },
    {
      "metadata": {
        "id": "f4qM5U0SRbR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# At test time:\n",
        "layer_output *= 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlRkuKm9RbSF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note that this process can be implemented by doing both operations at training time and leaving the output unchanged at test time, which is \n",
        "often the way it is implemented in practice:"
      ]
    },
    {
      "metadata": {
        "id": "9YXnTqGaRbSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# At training time:\n",
        "layer_output *= np.randint(0, high=2, size=layer_output.shape)\n",
        "# Note that we are scaling *up* rather scaling *down* in this case\n",
        "layer_output /= 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Cl-JpUJRbSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "This technique may seem strange and arbitrary. Why would this help reduce overfitting? Geoff Hinton has said that he was inspired, among \n",
        "other things, by a fraud prevention mechanism used by banks -- in his own words: _\"I went to my bank. The tellers kept changing and I asked \n",
        "one of them why. He said he didnt know but they got moved around a lot. I figured it must be because it would require cooperation \n",
        "between employees to successfully defraud the bank. This made me realize that randomly removing a different subset of neurons on each \n",
        "example would prevent conspiracies and thus reduce overfitting\"_.\n",
        "\n",
        "The core idea is that introducing noise in the output values of a layer can break up happenstance patterns that are not significant (what \n",
        "Hinton refers to as \"conspiracies\"), which the network would start memorizing if no noise was present. \n",
        "\n",
        "In Keras you can introduce dropout in a network via the `Dropout` layer, which gets applied to the output of layer right before it, e.g.:"
      ]
    },
    {
      "metadata": {
        "id": "LKXS2k8MRbSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(layers.Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X29hg6HnRbSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's add two `Dropout` layers in our IMDB network to see how well they do at reducing overfitting:"
      ]
    },
    {
      "metadata": {
        "id": "qGCTUyplRbSb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dpt_model = models.Sequential()\n",
        "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(16, activation='relu'))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "dpt_model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wv2D6q1-RbSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "02128e44-4138-4db5-cd48-e81ccb3b3872"
      },
      "cell_type": "code",
      "source": [
        "dpt_model_hist = dpt_model.fit(x_train, y_train,\n",
        "                               epochs=20,\n",
        "                               batch_size=512,\n",
        "                               validation_data=(x_test, y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 5s 187us/step - loss: 0.5900 - acc: 0.6845 - val_loss: 0.4306 - val_acc: 0.8618\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.4352 - acc: 0.8182 - val_loss: 0.3484 - val_acc: 0.8700\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.3475 - acc: 0.8706 - val_loss: 0.2915 - val_acc: 0.8864\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.2893 - acc: 0.8982 - val_loss: 0.2762 - val_acc: 0.8884\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.2553 - acc: 0.9128 - val_loss: 0.2801 - val_acc: 0.8880\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.2241 - acc: 0.9256 - val_loss: 0.2885 - val_acc: 0.8860\n",
            "Epoch 7/20\n",
            "19456/25000 [======================>.......] - ETA: 0s - loss: 0.1994 - acc: 0.9341"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1999 - acc: 0.9342 - val_loss: 0.3182 - val_acc: 0.8862\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1807 - acc: 0.9414 - val_loss: 0.3279 - val_acc: 0.8848\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1751 - acc: 0.9436 - val_loss: 0.3519 - val_acc: 0.8839\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1560 - acc: 0.9473 - val_loss: 0.3707 - val_acc: 0.8828\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.1485 - acc: 0.9505 - val_loss: 0.3895 - val_acc: 0.8811\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 133us/step - loss: 0.1414 - acc: 0.9557 - val_loss: 0.4416 - val_acc: 0.8741\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1281 - acc: 0.9580 - val_loss: 0.4448 - val_acc: 0.8786\n",
            "Epoch 14/20\n",
            "11776/25000 [=============>................] - ETA: 1s - loss: 0.1185 - acc: 0.9606"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.1242 - acc: 0.9580 - val_loss: 0.4544 - val_acc: 0.8768\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.1205 - acc: 0.9606 - val_loss: 0.4800 - val_acc: 0.8720\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1188 - acc: 0.9620 - val_loss: 0.5293 - val_acc: 0.8734\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.1133 - acc: 0.9613 - val_loss: 0.5287 - val_acc: 0.8747\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 130us/step - loss: 0.1151 - acc: 0.9632 - val_loss: 0.5402 - val_acc: 0.8739\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1024 - acc: 0.9654 - val_loss: 0.5707 - val_acc: 0.8732\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 131us/step - loss: 0.1073 - acc: 0.9666 - val_loss: 0.5796 - val_acc: 0.8723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6_UrjMgjRbSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot the results:"
      ]
    },
    {
      "metadata": {
        "id": "n3hKAQzRRbSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "604c4f71-dcc6-40d7-e598-e36e756149de"
      },
      "cell_type": "code",
      "source": [
        "dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHTkDjYOlLFAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdef38a7518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D1An7yqhRbTP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Again, a clear improvement over the reference network.\n",
        "\n",
        "To recap: here the most common ways to prevent overfitting in neural networks:\n",
        "\n",
        "* Getting more training data.\n",
        "* Reducing the capacity of the network.\n",
        "* Adding weight regularization.\n",
        "* Adding dropout."
      ]
    }
  ]
}